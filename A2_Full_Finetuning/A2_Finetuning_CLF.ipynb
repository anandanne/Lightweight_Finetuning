{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import nethook\n",
    "from utils import model_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-medium\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=False)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple has recently released their iPhone 14 line of\n",
      "Apple has recently released their iPhone 14 line of smartphones, and while they've had some issues with the battery, they've been able to fix them.  In fact, they've even managed to fix the issue of the iPhone battery dying in the\n",
      "p(answer):  p(' devices'[4410])=0.2049, p(' phones'[9512])=0.1882, p(' smartphones'[18151])=0.1707, p(' hands'[2832])=0.0887, p(' products'[3186])=0.0367\n",
      "\n",
      "Goole has released Pixel 7\n",
      "Goole has released Pixel 7.0.0. It is the first time Google has released a software update for its flagship handset in over a year. The update comes in at 4.5GB and includes a fix for an issue which caused\n",
      "p(answer):  p(' and'[290])=0.1817, p(','[11])=0.0804, p('.'[13])=0.0659, p(' Plus'[8227])=0.0247, p(' on'[319])=0.0194\n",
      "\n",
      "I am taking a Machine Learning class\n",
      "I am taking a Machine Learning class. I am taking a class that is about Artificial Neural Networks and I am taking a class that is about Neural Networks. The course is called Machine Learning and I am taking this class to learn how to do that.\n",
      "p(answer):  p(' at'[379])=0.198, p(' in'[287])=0.0797, p(' with'[351])=0.071, p('.'[13])=0.0633, p(' and'[290])=0.0631\n",
      "\n",
      "Eiffel Tower is in Paris.\n",
      "Eiffel Tower is in Paris.  A French woman is seen in a video being arrested in a shopping centre in Paris on Tuesday, April 14, 2014. Police are searching for two people suspected of trying to rob an elderly French woman.\n",
      "p(answer):  p('\n",
      "'[198])=0.2083, p(' The'[383])=0.1101, p(' It'[632])=0.075, p(' In'[554])=0.0222, p(' I'[314])=0.0214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    \"Apple has recently released their iPhone 14 line of\",\n",
    "    \"Goole has released Pixel 7\",\n",
    "    \"I am taking a Machine Learning class\",\n",
    "    \"Eiffel Tower is in Paris.\"\n",
    "]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = False,\n",
    "    max_out_len= 50,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader (the `GoEmotions` dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>You're waiting to see if the remake is better ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11896</th>\n",
       "      <td>H.G. Wells in 1936 was past his prime and the ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12219</th>\n",
       "      <td>It seems that Salvatores couldn't decide what ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27402</th>\n",
       "      <td>One of the major aspects of \"Malenkaya Vera\" (...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25995</th>\n",
       "      <td>remember back when this movie was made by robe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "3234   You're waiting to see if the remake is better ...  positive\n",
       "11896  H.G. Wells in 1936 was past his prime and the ...  positive\n",
       "12219  It seems that Salvatores couldn't decide what ...  negative\n",
       "27402  One of the major aspects of \"Malenkaya Vera\" (...  positive\n",
       "25995  remember back when this movie was made by robe...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/IMDB_50K_Reviews/archive/IMDB Dataset.csv\")\n",
    "df = df.sample(frac = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're waiting to see if the remake is better or worse. I rated the Audie Murphy movie a 3 (I'm a harsh grader), the second lowest I ever gave Audie (the worst being \"Battle at Bloody Beach\" if you're curious). I give this movie a rating of \"8\" (and I'm a harsh grader) It's the Civil War story of renegade \"soldiers\", if you want to call them that, against the North. People like Quantrell, and the men who rode with these outlaws.<br /><br />The original was a watery version, very clean cut, while still depicting the horror of what these men did. Actually, movies such as the older version are best viewed by mature audiences, who can discern the story. I would be more apt to rate the original \"R\" and this one, with it's gruff nature, a GP, because the newer movie gives a very honest version, a message more easily deciphered by a juvenile than the older version.<br /><br />Film makers since the early sixties have boasted about \"Realism\", but few of them deliver. Instead, they just give the drab scenery, drab costumes, and drab events, but with comic book cardboard stereotype characters, the weakness of the spaghetti era.<br /><br />Modern film makers have realized this mistake. It is evident in a superior style of Western we usually see today. This movie is an example. It gives the realistic settings, but also gives us characters we can believe exist in that era.<br /><br />It has a few lulls, which makes a complete sit through a bit hard, and it has some unexplained situations. But unexplained situations are okay as long the entire movie holds up, and the characters are intriguing enough.<br /><br />It begins a bit campy, but really improves. The main character is one we can identify, and at least have some sympathy for. The Audie Murphy character of the early movie really evokes no sympathy, and is too self righteous without motivation.<br /><br />The character in this movie follows the lines of a true anti-hero. There is motivation, and a method to his madness. We never feel he is truly \"right\", but we can understand where he comes from.<br /><br />There is plenty of action in the movie. There is also some humor. One good scene is when the heroine tells the hero she wouldn't lie to him, and he mulls that over.<br /><br />This movie succeeds in doing what film makers have been trying to do for decades. This director and writer team got it right.<br /><br />Recommended. Complete success.\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row[\"review\"])\n",
    "    print(row[\"sentiment\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[0:30000]\n",
    "validation_df = df[30000:40000]\n",
    "test_df = df[40000:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 2), (10000, 2), (10000, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, validation_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import re\n",
    "CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});|/.*/')\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  raw_html = raw_html.replace(\"\\\\\", \"\")\n",
    "  raw_html = raw_html.replace(\"&#039;\", \"\\'\")\n",
    "  cleantext = re.sub(CLEANR, ' ', raw_html)\n",
    "  split = cleantext.strip().split(\" \")\n",
    "  if(split[0].isnumeric()):\n",
    "    split = split[1:]\n",
    "  return \" \".join([w for w in split if len(w.strip()) > 0])\n",
    "\n",
    "# cleanhtml(\"Don&#039;t mess with me\")\n",
    "# cleanhtml('<a href=\"#p79290593\" class=\"quotelink\">&gt;&gt;79290593</a><br><span class=\"quote\">&gt;canada</span><br><br>and you faggots think we&#039;re the worst shit posters')\n",
    "\n",
    "class GoEmotions(Dataset):\n",
    "    def __init__(self, data_frame):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "\n",
    "        for index, row in data_frame.iterrows():\n",
    "            self.x.append(\"<REVIEW>: \" + cleanhtml(row[\"review\"]) + \" <SENTIMENT>\")\n",
    "            self.y.append(\" \" + row[\"sentiment\"])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 10000, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = GoEmotions(train_df)\n",
    "validation_dataset = GoEmotions(validation_df)\n",
    "test_dataset = GoEmotions(test_df)\n",
    "\n",
    "len(training_dataset), len(validation_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testing_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = \"transformer.wte\"\n",
    "layer_norm_final = \"transformer.ln_f\"\n",
    "unembedder = \"lm_head\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "learning_rate = 5e-4\n",
    "warmup_steps = 200\n",
    "weight_decay = 0\n",
    "\n",
    "optimization_batch_size = 8\n",
    "max_token_per_comment = 963\n",
    "\n",
    "save_path = f\"../Saved_weights/Fine-Tuned_CLF__IMDB_50K/{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 63/15000 [00:09<47:41,  5.22it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 15000/15000 [36:37<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [36:38<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [37:19<00:00,  6.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "tunable_weights = {\n",
    "    n: p\n",
    "    for n, p in model.named_parameters()\n",
    "    if n.startswith(\"transformer.h.\")       # only tune the layers, leave the embedding and unembedding alone\n",
    "}\n",
    "# print(f\"Weights to be updated: {list(tunable_weights.keys())}\")\n",
    "\n",
    "for name, w in model.named_parameters():\n",
    "    w.requires_grad = name in tunable_weights\n",
    "\n",
    "# optimizer = AdamW(\n",
    "#     # model.parameters(),\n",
    "#     [v for _, v in tunable_weights.items()],\n",
    "#     lr = learning_rate,\n",
    "# )\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
    "# )\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [v for _, v in tunable_weights.items()],\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    ")\n",
    "\n",
    "num_prompts_optimized = 0\n",
    "training_loss_track = []\n",
    "validation_loss_track = []\n",
    "\n",
    "target_track = {\n",
    "    \" positive\": 0,\n",
    "    \" negative\": 0\n",
    "}\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    for reviews, sentiments in tqdm(training_dataloader):\n",
    "        tokenized_inputs = tokenizer(\n",
    "            list(reviews),\n",
    "            padding = True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(next(model.parameters()).device)\n",
    "\n",
    "        if(tokenized_inputs['input_ids'].shape[1] > max_token_per_comment):\n",
    "            # print(f\"BLOCKED ==> {tokenized_inputs['input_ids'].shape[1]}\")\n",
    "            continue\n",
    "            \n",
    "        for t in sentiments:\n",
    "            target_track[t] += 1\n",
    "\n",
    "        target_ids = tokenizer(\n",
    "            list(sentiments), \n",
    "            padding = True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(next(model.parameters()).device)['input_ids']\n",
    "\n",
    "        # print(sentiments)\n",
    "\n",
    "        # print(tokenized_inputs['input_ids'].shape)\n",
    "        # print(sentiments, target_ids)\n",
    "\n",
    "        last_token_inds = tokenized_inputs[\"attention_mask\"].sum(dim=1) - 1\n",
    "        loss_mask = target_ids != tokenizer.unk_token_id\n",
    "\n",
    "        # print(last_token_inds)\n",
    "        # print(loss_mask)\n",
    "\n",
    "        # with nethook.TraceDict(\n",
    "        #     model,\n",
    "        #     [embedder, layer_norm_final, unembedder],\n",
    "        # ) as traces:\n",
    "        outputs = model(\n",
    "            **tokenized_inputs, \n",
    "        )\n",
    "\n",
    "        probs = torch.nn.functional.log_softmax(\n",
    "            outputs.logits[torch.arange(batch_size), last_token_inds], dim=-1\n",
    "        )\n",
    "        # print(probs)\n",
    "\n",
    "        loss = -(torch.gather(probs, 1, target_ids) * loss_mask).sum(1) / loss_mask.sum(1)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        training_loss_track.append(loss.item())\n",
    "\n",
    "        # print(loss)\n",
    "        # break\n",
    "\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # num_prompts_optimized += batch_size\n",
    "        # if(True or num_prompts_optimized % optimization_batch_size):\n",
    "        #     training_loss_track.append(loss.item())\n",
    "\n",
    "        #     optimizer.step()\n",
    "        #     scheduler.step()\n",
    "            \n",
    "        #     optimizer.zero_grad()\n",
    "        #     model.zero_grad()\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n"
     ]
    }
   ],
   "source": [
    "print(\"#####################  CHECKPOINT -- saving weights #####################\")\n",
    "os.makedirs(save_path, exist_ok = True)\n",
    "torch.save(model.state_dict(), f\"{save_path}/finetuned_{num_prompts_optimized}.pth\")\n",
    "with open(f\"{save_path}/loss_track_{num_prompts_optimized}.json\", \"w\") as f:\n",
    "    json.dump({\"training\": training_loss_track, \"validation\": validation_loss_track}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fee4304b280>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(training_loss_track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint\n",
      "loaded model weights\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('../Saved_weights/Fine-Tuned_CLF__IMDB_50K/gpt2-medium/finetuned_0.pth')\n",
    "print(\"loaded checkpoint\")\n",
    "model.load_state_dict(checkpoint)\n",
    "print(\"loaded model weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<REVIEW>: This was an awesome movie <SENTIMENT> positive negative negative negative positive\n",
      "p(answer):  p(' positive'[3967])=0.9482, p(' negative'[4633])=0.0517, p(' Positive'[33733])=0.0, p(' positives'[38548])=0.0, p('positive'[24561])=0.0\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<REVIEW>: This was a bad movie <SENTIMENT> negative positive positive positive positive\n",
      "p(answer):  p(' negative'[4633])=0.8058, p(' positive'[3967])=0.1941, p(' Negative'[36183])=0.0, p(' Positive'[33733])=0.0, p(' positives'[38548])=0.0\n",
      "\n",
      "<REVIEW>: This movie is gross <SENTIMENT>\n",
      "<REVIEW>: This movie is gross <SENTIMENT> negative positive positive positive positive positive\n",
      "p(answer):  p(' negative'[4633])=0.5934, p(' positive'[3967])=0.4065, p(' Positive'[33733])=0.0, p(' Negative'[36183])=0.0, p(' positives'[38548])=0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    \"This was an awesome movie\",\n",
    "    \"This was a bad movie\",\n",
    "    \"This movie is gross\"\n",
    "]\n",
    "\n",
    "prompt = [\"<REVIEW>: \" + p + \" <SENTIMENT>\" for p in prompt]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 20,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [2:03:28<00:00,  3.70s/it]  \n"
     ]
    }
   ],
   "source": [
    "testing_dataloader = DataLoader(test_dataset, batch_size=5)\n",
    "\n",
    "target = []\n",
    "predict = []\n",
    "\n",
    "for reviews, sentiment in tqdm(testing_dataloader):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        list(reviews),\n",
    "        padding = True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(next(model.parameters()).device)\n",
    "\n",
    "    if(tokenized_inputs['input_ids'].shape[1] > max_token_per_comment):\n",
    "        # print(f\"BLOCKED ==> {tokenized_inputs['input_ids'].shape[1]}\")\n",
    "        continue\n",
    "\n",
    "    last_token_inds = tokenized_inputs[\"attention_mask\"].sum(dim=1)\n",
    "    max_out_len = max(last_token_inds).item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        txt, ret_dict = model_utils.generate_fast(\n",
    "            model, tokenizer,\n",
    "            list(reviews),\n",
    "            argmax_greedy = True,\n",
    "            max_out_len= max_out_len + 3,\n",
    "            # debug=True,\n",
    "            get_answer_tokens=True,\n",
    "        )\n",
    "\n",
    "    for t, p in zip(list(sentiment), ret_dict['answer']):\n",
    "        target.append(t)\n",
    "        predict.append(p['top_token'])\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4123 855\n",
      "431 3891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(target, predict).ravel()\n",
    "\n",
    "print(tp, fp)\n",
    "print(fn, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8626031101983391"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity = tp/(tp + fn)\n",
    "specificity = tn/(tn + fp)\n",
    "balanced_acc = (sensitivity + specificity)/2\n",
    "\n",
    "balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3835239043501baad7b502b0573c70a3454f6c2753902e68361683a11a30d10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
