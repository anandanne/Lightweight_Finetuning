{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driving GPT\n",
    "### Original Idea from [Geval et al](https://arxiv.org/abs/2203.14680)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from utils import nethook\n",
    "from utils import model_utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"EleutherAI/gpt-j-6B\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=False)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' nurse'[15849] -- 6.068979740142822 [' nurse'(6.069) ' teacher'(5.602) ' secretary'(1.812) ' n'(1.345) ' home'(1.342) ]\n",
      "' in'[287] -- 33.661949157714844 [' in'(33.662) ' and'(14.851) ' at'(12.634) ','(7.291) '.'(5.623) ]\n",
      "' a'[257] -- 39.44446563720703 [' a'(39.444) ' the'(16.802) ' an'(4.576) ' one'(1.255) ' India'(0.973) ]\n",
      "' hospital'[4436] -- 22.863826751708984 [' hospital'(22.864) ' private'(6.094) ' local'(4.439) ' small'(3.875) ' nursing'(2.57) ]\n",
      "'.'[13] -- 22.47379493713379 ['.'(22.474) ' in'(20.212) ' and'(19.487) ','(12.974) ' where'(1.826) ]\n",
      "' She'[1375] -- 28.857473373413086 [' She'(28.857) ' I'(11.856) ' We'(7.507) ' It'(4.27) ' The'(4.195) ]\n",
      "' is'[318] -- 17.278675079345703 [' is'(17.279) ' has'(16.177) ' works'(7.077) ''s'(4.559) '�'(3.953) ]\n",
      "' a'[257] -- 13.215200424194336 [' a'(13.215) ' working'(4.274) ' on'(3.667) ' very'(3.421) ' in'(3.239) ]\n",
      "' very'[845] -- 10.159626007080078 [' very'(10.16) ' nurse'(6.243) ' registered'(3.813) ' single'(3.34) ' good'(3.317) ]\n",
      "' good'[922] -- 15.36991024017334 [' good'(15.37) ' hard'(8.591) ' kind'(5.014) ' nice'(4.597) ' caring'(4.38) ]\n",
      "' nurse'[15849] -- 72.4891128540039 [' nurse'(72.489) ' and'(5.26) ' person'(5.238) ' one'(1.954) ','(1.855) ]\n",
      "','[11] -- 27.082246780395508 [','(27.082) '.'(25.057) ' and'(22.662) ' but'(9.868) ' who'(2.879) ]\n",
      "' but'[475] -- 35.00406265258789 [' but'(35.004) ' and'(18.784) ' she'(5.598) ' very'(3.927) ' with'(1.599) ]\n",
      "' she'[673] -- 40.14490509033203 [' she'(40.145) ' I'(4.654) ' the'(4.596) ' her'(3.073) ' has'(2.768) ]\n",
      "' is'[318] -- 30.18265724182129 [' is'(30.183) ' has'(16.736) ' doesn'(3.27) ' does'(2.922) ' gets'(2.841) ]\n",
      "' not'[407] -- 11.613853454589844 [' not'(11.614) ' also'(7.938) ' very'(6.959) ' a'(4.266) ' having'(3.82) ]\n",
      "' a'[257] -- 15.8876371383667 [' a'(15.888) ' happy'(12.153) ' very'(7.981) ' getting'(4.585) ' allowed'(2.999) ]\n",
      "' very'[845] -- 17.071849822998047 [' very'(17.072) ' good'(15.158) ' nurse'(12.758) ' doctor'(5.983) ' great'(2.279) ]\n",
      "' good'[922] -- 70.10834503173828 [' good'(70.108) ' happy'(4.138) ' nice'(3.896) ' patient'(1.558) ' efficient'(0.978) ]\n",
      "' mother'[2802] -- 17.457809448242188 [' mother'(17.458) ' person'(14.183) ' wife'(13.258) ' manager'(4.809) ' administrator'(3.607) ]\n",
      "'.'[13] -- 80.48995208740234 ['.'(80.49) ','(4.728) ' to'(3.573) ' because'(1.88) ' and'(1.359) ]\n",
      "' She'[1375] -- 36.20889663696289 [' She'(36.209) ' I'(13.381) '\n",
      "'(5.422) ' We'(5.332) ' When'(2.694) ]\n",
      "' is'[318] -- 25.091684341430664 [' is'(25.092) ' has'(12.825) ' works'(4.397) ' does'(4.308) ' doesn'(3.87) ]\n",
      "' always'[1464] -- 10.526315689086914 [' always'(10.526) ' a'(9.045) ' not'(8.288) ' very'(7.386) ' too'(2.707) ]\n",
      "' working'[1762] -- 16.383075714111328 [' working'(16.383) ' tired'(12.401) ' busy'(6.264) ' too'(5.73) ' on'(4.909) ]\n",
      "','[11] -- 29.867359161376953 [','(29.867) ' and'(26.613) '.'(14.577) ' late'(5.533) ' long'(2.247) ]\n",
      "' and'[290] -- 44.837745666503906 [' and'(44.838) ' she'(7.454) ' so'(4.961) ' always'(4.404) ' never'(2.118) ]\n",
      "' she'[673] -- 26.558053970336914 [' she'(26.558) ' I'(8.526) ' when'(7.491) ' the'(3.817) ' is'(3.142) ]\n",
      "' is'[318] -- 30.79806900024414 [' is'(30.798) ' has'(10.386) ' doesn'(8.936) ' does'(5.325) ' never'(4.491) ]\n",
      "' always'[1464] -- 24.486312866210938 [' always'(24.486) ' not'(13.598) ' never'(10.745) ' very'(5.022) ' often'(3.249) ]\n",
      "' tired'[10032] -- 41.26582717895508 [' tired'(41.266) ' exhausted'(6.009) ' on'(5.929) ' stressed'(3.038) ' busy'(2.835) ]\n",
      "'.'[13] -- 62.45772933959961 ['.'(62.458) ','(18.683) ' and'(7.158) ' when'(3.773) ' because'(1.179) ]\n",
      "' She'[1375] -- 32.53840637207031 [' She'(32.538) ' I'(13.421) '\n",
      "'(4.972) ' When'(4.835) ' So'(3.555) ]\n",
      "' is'[318] -- 24.098501205444336 [' is'(24.099) ' has'(12.033) ' does'(6.97) ' doesn'(6.308) ' never'(2.932) ]\n",
      "' always'[1464] -- 14.349026679992676 [' always'(14.349) ' not'(12.251) ' a'(9.091) ' also'(6.919) ' very'(5.698) ]\n",
      "' in'[287] -- 5.630443096160889 [' in'(5.63) ' on'(5.406) ' working'(5.2) ' complaining'(4.815) ' tired'(3.943) ]\n",
      "' a'[257] -- 53.07660675048828 [' a'(53.077) ' the'(15.192) ' and'(8.477) ' bed'(3.503) ' her'(3.182) ]\n",
      "' hurry'[23290] -- 50.57457733154297 [' hurry'(50.575) ' bad'(28.681) ' rush'(15.084) ' state'(0.501) ' good'(0.466) ]\n",
      "'.'[13] -- 40.77106475830078 ['.'(40.771) ','(26.075) ' to'(20.011) ' and'(6.799) ' because'(1.333) ]\n",
      "' She'[1375] -- 48.41164779663086 [' She'(48.412) ' I'(9.198) '\n",
      "'(5.794) ' When'(4.536) ' And'(3.748) ]\n",
      "' is'[318] -- 37.163822174072266 [' is'(37.164) ' does'(8.759) ' has'(7.125) ' doesn'(7.12) ' never'(4.621) ]\n",
      "' always'[1464] -- 47.50973129272461 [' always'(47.51) ' not'(9.399) ' never'(7.036) ' a'(5.409) ' very'(4.273) ]\n",
      "' rushing'[15795] -- 10.898138046264648 [' rushing'(10.898) ' in'(6.28) ' on'(5.477) ' busy'(4.039) ' running'(3.802) ]\n",
      "' to'[284] -- 17.75979232788086 [' to'(17.76) '.'(13.565) ' around'(13.551) ' from'(10.51) ' somewhere'(5.462) ]\n",
      "My wife is working as a\n",
      "My wife is working as a nurse in a hospital. She is a very good nurse, but she is not a very good mother. She is always working, and she is always tired. She is always in a hurry. She is always rushing to\n",
      "p(answer):  p(' nurse'[15849])=0.0607, p(' teacher'[4701])=0.056, p(' secretary'[7705])=0.0181, p(' n'[299])=0.0135, p(' home'[1363])=0.0134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\"My wife is working as a\"]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 50,\n",
    "    debug=True,\n",
    "    get_answer_tokens=True,\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'top_token': ' nurse',\n",
       "  'candidates': [{'token': ' nurse', 'token_id': 15849, 'p': 0.0607},\n",
       "   {'token': ' teacher', 'token_id': 4701, 'p': 0.056},\n",
       "   {'token': ' secretary', 'token_id': 7705, 'p': 0.0181},\n",
       "   {'token': ' n', 'token_id': 299, 'p': 0.0135},\n",
       "   {'token': ' home', 'token_id': 1363, 'p': 0.0134}]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, value in model.named_parameters():\n",
    "#     print(name, \" :: \", value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and store the vocabs promoted by each of the MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unembedding = nethook.get_module(model, \"lm_head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_out_format = \"transformer.h.{}.mlp.fc_out.weight\"\n",
    "def get_tokens_promoted_by_fc_proj_at_layer(model, layer_no, k = 100):\n",
    "    param = nethook.get_parameter(model, fc_out_format.format(layer_no))\n",
    "    ret = {}\n",
    "    for col in tqdm(range(param.shape[1])):\n",
    "        logits = unembedding(param[:, col])\n",
    "        softmax = torch.nn.functional.softmax(logits, dim = 0)\n",
    "        top_k = torch.topk(softmax, k = k)\n",
    "        \n",
    "        ret[f'column_{col}'] = {\n",
    "            tokenizer.decode(idx): {\"p\": softmax[idx].item(), \"idx\": idx.item()}\n",
    "            for idx in top_k.indices\n",
    "        }\n",
    "        # break\n",
    "    return ret\n",
    "\n",
    "# get_tokens_promoted_by_fc_proj_at_layer(model, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:23<00:00, 50.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:23<00:00, 50.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:25<00:00, 50.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:22<00:00, 50.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:23<00:00, 50.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:23<00:00, 50.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:24<00:00, 50.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:25<00:00, 50.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:24<00:00, 50.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:23<00:00, 50.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:23<00:00, 50.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:23<00:00, 50.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:22<00:00, 50.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:15<00:00, 51.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:18<00:00, 51.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:20<00:00, 51.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:24<00:00, 50.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:23<00:00, 50.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:18<00:00, 51.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:21<00:00, 50.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:22<00:00, 50.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:22<00:00, 50.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:25<00:00, 50.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:25<00:00, 50.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:20<00:00, 51.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:23<00:00, 50.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:21<00:00, 50.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving vocabs promoted by layer 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [05:21<00:00, 50.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for layer in range(model.config.n_layer):\n",
    "    print(f\"saving vocabs promoted by layer {layer}\")\n",
    "    promoted_vocabs = get_tokens_promoted_by_fc_proj_at_layer(model, layer, k = 500)\n",
    "    with open(f\"fc_out_vocab/layer_{layer}.json\", 'w') as f:\n",
    "        json.dump(promoted_vocabs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3835239043501baad7b502b0573c70a3454f6c2753902e68361683a11a30d10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
