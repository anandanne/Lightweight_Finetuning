{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import nethook\n",
    "from utils import model_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-medium\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=False)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple has recently released their iPhone 14 line of\n",
      "Apple has recently released their iPhone 14 line of handsets, with the latest model coming out this week, and while it's a bit disappointing that they're going with a plastic body, there are some really interesting features in the latest iPhone.  \n",
      "p(answer):  p(' devices'[4410])=0.2049, p(' phones'[9512])=0.1882, p(' smartphones'[18151])=0.1707, p(' hands'[2832])=0.0887, p(' products'[3186])=0.0367\n",
      "\n",
      "Goole has released Pixel 7\n",
      "Goole has released Pixel 7.1.1 which brings a few fixes and security fixes.  Google has also updated its Android Marshmallow operating system for Nexus 6P, Nexus 9 and Pixel. This update brings a few security and stability\n",
      "p(answer):  p(' and'[290])=0.1817, p(','[11])=0.0804, p('.'[13])=0.0659, p(' Plus'[8227])=0.0247, p(' on'[319])=0.0194\n",
      "\n",
      "I am taking a Machine Learning class\n",
      "I am taking a Machine Learning class at my alma mater, and I am going to learn a lot of stuff.  I'm going to take a class called 'Machine Learning' in my first month.  I want to learn more\n",
      "p(answer):  p(' at'[379])=0.198, p(' in'[287])=0.0797, p(' with'[351])=0.071, p('.'[13])=0.0633, p(' and'[290])=0.0631\n",
      "\n",
      "Eiffel Tower is in Paris.\n",
      "Eiffel Tower is in Paris. The tower is the tallest structure in Europe. It was built in 1694 by the architect, Pierre-Auguste Courbet, to house the Royal Institute of Technology. The French Government decided to erect a monument\n",
      "p(answer):  p('\n",
      "'[198])=0.2083, p(' The'[383])=0.1101, p(' It'[632])=0.075, p(' In'[554])=0.0222, p(' I'[314])=0.0214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    \"Apple has recently released their iPhone 14 line of\",\n",
    "    \"Goole has released Pixel 7\",\n",
    "    \"I am taking a Machine Learning class\",\n",
    "    \"Eiffel Tower is in Paris.\"\n",
    "]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = False,\n",
    "    max_out_len= 50,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader (the `GoEmotions` dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43083</th>\n",
       "      <td>What we have here is a film about how the purs...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13797</th>\n",
       "      <td>Jared Diamond made a point in the first episod...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25228</th>\n",
       "      <td>Some people might call \"Paulie\" a kids' movie,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37655</th>\n",
       "      <td>The 1960's were a time of change and awakening...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>This movie is the last straw in a list of film...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "43083  What we have here is a film about how the purs...  negative\n",
       "13797  Jared Diamond made a point in the first episod...  negative\n",
       "25228  Some people might call \"Paulie\" a kids' movie,...  positive\n",
       "37655  The 1960's were a time of change and awakening...  negative\n",
       "4044   This movie is the last straw in a list of film...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/IMDB_50K_Reviews/archive/IMDB Dataset.csv\")\n",
    "df = df.sample(frac = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we have here is a film about how the pursuit of money & revenge can corrupt your soul... or something like that. Guy Ritchie, a director known for his reworking of the gangster genre, bites off more than he can chew with this one.<br /><br />His use of modern film noir to tackle the theme of a man setting himself free by swallowing his pride, being nice to his enemy & giving away all his money falls flat on it's face. When Jason Statham's character no longer fears Ray Liotta, it apparently drives Liotta crazy enough to blow his head off in the final scene. Why? Basically you cannot set up a mafiosi like the Liotta character, who has presumably got to his station in life by displaying the kind of ruthless behaviour evident throughout the film, only then to have him driven to suicide by nothing more than a pitying smile on the face of Statham's character.<br /><br />Before anyone starts to say I'm missing the point... I'm not. I get it OK? Opt out of the quest for riches & you'll find true happiness and inner peace. Be nice to your enemy and this will confuse him into self-destruction. This seems to be the gist of the movie and in itself this is not a bad premise for a story, although hardly original. The problem is that Ritchie simply doesn't have the skill as a movie maker to carry it off. At the moment when even Guy Ritchie realises this, he appears to get bored with the story and begins to insert red-herrings: The scene when Statham gets knocked over by a car - Why? The shooting of some scenes as Marvel comic animations... again, why?<br /><br />There are so many loose threads & unanswered questions left at the end of the movie you could get all 2001-ish about it and try figuring them out, or simply accept that there are no answers & each viewer will interpret things in their own way. Myself? I was so bored with the pompous tone of the film that I simply didn't care. Frankly the ending couldn't come too soon so that I didn't have to sit through any more of this pretentious psychobabble.<br /><br />A waste of two hours of my life.\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row[\"review\"])\n",
    "    print(row[\"sentiment\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[0:30000]\n",
    "validation_df = df[30000:40000]\n",
    "test_df = df[40000:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 2), (10000, 2), (10000, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, validation_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import re\n",
    "CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});|/.*/')\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  raw_html = raw_html.replace(\"\\\\\", \"\")\n",
    "  raw_html = raw_html.replace(\"&#039;\", \"\\'\")\n",
    "  cleantext = re.sub(CLEANR, ' ', raw_html)\n",
    "  split = cleantext.strip().split(\" \")\n",
    "  if(split[0].isnumeric()):\n",
    "    split = split[1:]\n",
    "  return \" \".join([w for w in split if len(w.strip()) > 0])\n",
    "\n",
    "# cleanhtml(\"Don&#039;t mess with me\")\n",
    "# cleanhtml('<a href=\"#p79290593\" class=\"quotelink\">&gt;&gt;79290593</a><br><span class=\"quote\">&gt;canada</span><br><br>and you faggots think we&#039;re the worst shit posters')\n",
    "\n",
    "class GoEmotions(Dataset):\n",
    "    def __init__(self, data_frame):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "\n",
    "        for index, row in data_frame.iterrows():\n",
    "            self.x.append(\"<REVIEW>: \" + cleanhtml(row[\"review\"]) + \" <SENTIMENT>\")\n",
    "            self.y.append(\" \" + row[\"sentiment\"])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 10000, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = GoEmotions(train_df)\n",
    "validation_dataset = GoEmotions(validation_df)\n",
    "test_dataset = GoEmotions(test_df)\n",
    "\n",
    "len(training_dataset), len(validation_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testing_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = \"transformer.wte\"\n",
    "layer_norm_final = \"transformer.ln_f\"\n",
    "unembedder = \"lm_head\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "prefix_size = 20\n",
    "num_epochs = 10\n",
    "###############################################################################################################\n",
    "\n",
    "learning_rate = 5e-4\n",
    "warmup_steps = 200\n",
    "weight_decay = 0\n",
    "\n",
    "optimization_batch_size = 8\n",
    "max_token_per_comment = 963\n",
    "\n",
    "save_path = f\"../Saved_weights/Promt-Tuned_CLF__IMDB_50K/{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_module = nethook.get_module(model, embedder)\n",
    "lm_head = nethook.get_module(model, unembedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 1024])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "init_words = [\"sentiment\", \"elephant\", \"review\"]\n",
    "def get_initial_prefix(prefix_size = 5):\n",
    "    words = random.choices(init_words, k=prefix_size)\n",
    "    sentence = \" \" + \" \".join(words)\n",
    "    tokenized = tokenizer(sentence, return_tensors = \"pt\").to(next(model.parameters()).device)\n",
    "    return embedder_module(tokenized['input_ids'])\n",
    "\n",
    "get_initial_prefix(7).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.n_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)\n",
      "torch.Size([2, 23, 1024]) torch.Size([2, 23, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "soft_embeddings = get_initial_prefix(prefix_size)\n",
    "init_state = copy.deepcopy(soft_embeddings)\n",
    "soft_embeddings.requires_grad  = True\n",
    "\n",
    "print((init_state - soft_embeddings).norm())\n",
    "\n",
    "# def insert_prompt_embeddings(output, layer, soft_embeddings = soft_embeddings):\n",
    "#     if(layer != embedder):\n",
    "#         return output\n",
    "#     print(output.requires_grad, soft_embeddings.requires_grad)\n",
    "#     prefix_size = soft_embeddings.shape[1]\n",
    "#     for batch in output:\n",
    "#         batch[0:prefix_size] = soft_embeddings\n",
    "#     return output\n",
    "\n",
    "def insert_prompt_embeddings_2(output, layer, soft_embeddings = soft_embeddings):\n",
    "    if(layer != embedder):\n",
    "        return output\n",
    "    prefix_size = soft_embeddings.shape[1]\n",
    "    arr = []\n",
    "    for batch in output:\n",
    "        added = torch.cat((soft_embeddings[0], batch[prefix_size:, :]))\n",
    "        arr.append(added)\n",
    "    return torch.stack(arr)\n",
    "\n",
    "inner_rep = torch.randn([2, 23, model.config.n_embd]).to(next(model.parameters()).device)\n",
    "prefix_added = insert_prompt_embeddings_2(inner_rep, embedder)\n",
    "\n",
    "print(inner_rep.shape, prefix_added.shape)\n",
    "(inner_rep[..., prefix_size:, :] - prefix_added[..., prefix_size:, :]).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0402, -0.0731,  0.0385,  ...,  0.0422, -0.0059, -0.0381],\n",
      "         [-0.2413, -0.0916, -0.0155,  ...,  0.0148, -0.0138, -0.1585],\n",
      "         [-0.0402, -0.0731,  0.0385,  ...,  0.0422, -0.0059, -0.0381],\n",
      "         ...,\n",
      "         [-0.2413, -0.0916, -0.0155,  ...,  0.0148, -0.0138, -0.1585],\n",
      "         [-0.1227, -0.0664,  0.1448,  ...,  0.0807,  0.0043, -0.0249],\n",
      "         [-0.2413, -0.0916, -0.0155,  ...,  0.0148, -0.0138, -0.1585]]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(soft_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/15000 [00:00<25:23,  9.84it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 15000/15000 [28:36<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [29:44<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [27:21<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [25:47<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [25:47<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [25:49<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [25:53<00:00,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [25:54<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [25:46<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [28:52<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "# optimizer = AdamW(\n",
    "#     # model.parameters(),\n",
    "#     [v for _, v in tunable_weights.items()],\n",
    "#     lr = learning_rate,\n",
    "# )\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
    "# )\n",
    "\n",
    "\n",
    "for name, w in model.named_parameters():\n",
    "    w.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [soft_embeddings],\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    ")\n",
    "\n",
    "num_prompts_optimized = 0\n",
    "training_loss_track = []\n",
    "validation_loss_track = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    for reviews, sentiments in tqdm(training_dataloader):\n",
    "        tokenized_inputs = tokenizer(\n",
    "            list(reviews),\n",
    "            padding = True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(next(model.parameters()).device)\n",
    "\n",
    "        # add soft tokens\n",
    "        prefix_tokens = torch.ones(len(reviews), prefix_size, dtype = int).to(next(model.parameters()).device) * model.config.bos_token_id\n",
    "        tokenized_inputs[\"input_ids\"] = torch.cat((prefix_tokens, tokenized_inputs[\"input_ids\"]), dim = 1)\n",
    "        prefix_attn = torch.ones(len(reviews), prefix_size, dtype = int).to(next(model.parameters()).device)\n",
    "        tokenized_inputs[\"attention_mask\"] = torch.cat((prefix_attn, tokenized_inputs[\"attention_mask\"]), dim = 1)\n",
    "\n",
    "        if(tokenized_inputs['input_ids'].shape[1] > max_token_per_comment):\n",
    "            # print(f\"BLOCKED ==> {tokenized_inputs['input_ids'].shape[1]}\")\n",
    "            continue\n",
    "\n",
    "        target_ids = tokenizer(\n",
    "            list(sentiments), \n",
    "            padding = True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(next(model.parameters()).device)['input_ids']\n",
    "\n",
    "        # print(sentiments)\n",
    "\n",
    "        # print(tokenized_inputs['input_ids'].shape)\n",
    "        # print(sentiments, target_ids)\n",
    "\n",
    "        last_token_inds = tokenized_inputs[\"attention_mask\"].sum(dim=1) - 1\n",
    "        loss_mask = target_ids != tokenizer.unk_token_id\n",
    "\n",
    "        # tokenized[\"input_ids\"].require_grad = True\n",
    "        with nethook.TraceDict(\n",
    "            model,\n",
    "            [embedder, layer_norm_final, unembedder],\n",
    "            edit_output=insert_prompt_embeddings_2\n",
    "        ) as traces:\n",
    "            outputs = model(\n",
    "                **tokenized_inputs, \n",
    "                labels=tokenized_inputs['input_ids']\n",
    "            )\n",
    "\n",
    "        probs = torch.nn.functional.log_softmax(\n",
    "            outputs.logits[torch.arange(batch_size), last_token_inds], dim=-1\n",
    "        )\n",
    "        # print(probs)\n",
    "\n",
    "        loss = -(torch.gather(probs, 1, target_ids) * loss_mask).sum(1) / loss_mask.sum(1)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        training_loss_track.append(loss.item())\n",
    "\n",
    "        # print(loss)\n",
    "        # break\n",
    "\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # break\n",
    "        \n",
    "    print(\"#####################  CHECKPOINT -- saving weights #####################\")\n",
    "    os.makedirs(save_path, exist_ok = True)\n",
    "    torch.save(soft_embeddings, f\"{save_path}/promptuned__epoch_{epoch+1}.pth\")\n",
    "    with open(f\"{save_path}/loss_track_{epoch + 1}.json\", \"w\") as f:\n",
    "        json.dump({\"training\": training_loss_track, \"validation\": validation_loss_track}, f)\n",
    "        training_loss_track = []\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27.7416, device='cuda:0', grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(soft_embeddings - init_state).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9b505eb6a0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(training_loss_track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_embeddings = torch.load('../Saved_weights/Promt-Tuned_CLF__IMDB_50K/gpt2-medium/promptuned__epoch_10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was an awesome movie <SENTIMENT> positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.995, p(' negative'[4633])=0.0049, p(' positively'[19888])=0.0, p(' positives'[38548])=0.0, p(' good'[922])=0.0\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was a bad movie <SENTIMENT> negative, negative, negative\n",
      "p(answer):  p(' negative'[4633])=0.9986, p(' positive'[3967])=0.0014, p(' derogatory'[44094])=0.0, p(' bad'[2089])=0.0, p(' critical'[4688])=0.0\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was not a good movie <SENTIMENT> negative positive positive positive\n",
      "p(answer):  p(' negative'[4633])=0.996, p(' positive'[3967])=0.004, p(' critical'[4688])=0.0, p(' pro'[386])=0.0, p(' unfavorable'[38206])=0.0\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: That movie was garbage <SENTIMENT> negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.9967, p(' positive'[3967])=0.0033, p(' pro'[386])=0.0, p(' negativity'[45074])=0.0, p(' derogatory'[44094])=0.0\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: Iphone 7 is not a good phone <SENTIMENT> negative positive\n",
      "p(answer):  p(' negative'[4633])=0.9848, p(' positive'[3967])=0.0151, p(' Negative'[36183])=0.0, p(' pro'[386])=0.0, p(' negativity'[45074])=0.0\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: Google new line of pixels are great <SENTIMENT> positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.8062, p(' negative'[4633])=0.1937, p(' Positive'[33733])=0.0, p(' negatives'[42510])=0.0, p(' positives'[38548])=0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    \"This was an awesome movie\",\n",
    "    \"This was a bad movie\",\n",
    "    \"This was not a good movie\",\n",
    "    \"That movie was garbage\",\n",
    "    \"Iphone 7 is not a good phone\",\n",
    "    \"Google new line of pixels are great\"\n",
    "]\n",
    "\n",
    "prompt = [\"<REVIEW>: \" + p + \" <SENTIMENT>\" for p in prompt]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    "\n",
    "    prompt_tuning = soft_embeddings,\n",
    "    # track_interesting_words = [\n",
    "    #     [\" positive\", \" negative\"],\n",
    "    #     [\" positive\", \" negative\"]\n",
    "    # ]\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [2:09:05<00:00,  3.87s/it]  \n"
     ]
    }
   ],
   "source": [
    "testing_dataloader = DataLoader(test_dataset, batch_size=5)\n",
    "\n",
    "target = []\n",
    "predict = []\n",
    "\n",
    "for reviews, sentiment in tqdm(testing_dataloader):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        list(reviews),\n",
    "        padding = True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(next(model.parameters()).device)\n",
    "\n",
    "    if(tokenized_inputs['input_ids'].shape[1] > max_token_per_comment):\n",
    "        # print(f\"BLOCKED ==> {tokenized_inputs['input_ids'].shape[1]}\")\n",
    "        continue\n",
    "\n",
    "    last_token_inds = tokenized_inputs[\"attention_mask\"].sum(dim=1)\n",
    "    max_out_len = max(last_token_inds).item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        txt, ret_dict = model_utils.generate_fast(\n",
    "            model, tokenizer,\n",
    "            list(reviews),\n",
    "            argmax_greedy = True,\n",
    "            max_out_len= max_out_len + prefix_size + 3,\n",
    "            # debug=True,\n",
    "            get_answer_tokens=True,\n",
    "\n",
    "            prompt_tuning = soft_embeddings,\n",
    "        )\n",
    "\n",
    "    for t, p in zip(list(sentiment), ret_dict['answer']):\n",
    "        target.append(t)\n",
    "        predict.append(p['top_token'])\n",
    "\n",
    "    # print(txt, ret_dict['answer'])\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4371 230\n",
      "338 4331\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(target, predict).ravel()\n",
    "\n",
    "print(tp, fp)\n",
    "print(fn, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388975073691381"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity = tp/(tp + fn)\n",
    "specificity = tn/(tn + fp)\n",
    "balanced_acc = (sensitivity + specificity)/2\n",
    "\n",
    "balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rome')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3835239043501baad7b502b0573c70a3454f6c2753902e68361683a11a30d10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
