{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import nethook\n",
    "from utils import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-medium\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=False)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<REVIEW>: This was an awesome movie <SENTIMENT> <REVIEW>: I love this movie <REVIEW>: I love this movie <REVIEW>: I love this movie <\n",
      "p(answer):  p(' <'[1279])=0.0664, p('\n",
      "'[198])=0.0569, p(' :'[1058])=0.05, p(' I'[314])=0.0458, p(' It'[632])=0.0208\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<REVIEW>: This was a bad movie <SENTIMENT> <REVIEW>: I don't know what to say <REVIEW>: I'm not sure what to say <REVIEW\n",
      "p(answer):  p(' <'[1279])=0.0586, p(' :'[1058])=0.0528, p('\n",
      "'[198])=0.0445, p(' I'[314])=0.0341, p(' ('[357])=0.0278\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<REVIEW>: This was not a good movie <SENTIMENT> <REVIEW>: I don't think it was a good movie <REVIEW>: I think it was a good movie\n",
      "p(answer):  p(' <'[1279])=0.0508, p(' :'[1058])=0.0455, p(' I'[314])=0.0397, p('\n",
      "'[198])=0.0332, p(' ('[357])=0.0229\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<REVIEW>: That movie was garbage <SENTIMENT> <REVIEW>: I'm not going to watch it <REVIEW>: I'm not going to watch it <REVIEW>:\n",
      "p(answer):  p(' <'[1279])=0.0796, p('\n",
      "'[198])=0.0445, p(' ['[685])=0.0359, p(' :'[1058])=0.0331, p(' I'[314])=0.0305\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT> <REVIEW>: Iphone 7 is not a good phone <SENTIMENT> <REVIEW>:\n",
      "p(answer):  p(' <'[1279])=0.055, p(' I'[314])=0.0377, p(' :'[1058])=0.0246, p('\n",
      "'[198])=0.0221, p(' http'[2638])=0.022\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT> <REVIEW>: I'm not sure if this is a bug or a feature <REVIEW>: I'm not\n",
      "p(answer):  p(' <'[1279])=0.0745, p('\n",
      "'[198])=0.0385, p(' :'[1058])=0.0319, p(' ['[685])=0.0252, p(' http'[2638])=0.0225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    \"This was an awesome movie\",\n",
    "    \"This was a bad movie\",\n",
    "    \"This was not a good movie\",\n",
    "    \"That movie was garbage\",\n",
    "    \"Iphone 7 is not a good phone\",\n",
    "    \"Google new line of pixels are great\"\n",
    "]\n",
    "\n",
    "prompt = [\"<REVIEW>: \" + p + \" <SENTIMENT>\" for p in prompt]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    "\n",
    "    # track_interesting_words = [\n",
    "    #     [\" positive\", \" negative\"],\n",
    "    #     [\" positive\", \" negative\"]\n",
    "    # ]\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was an awesome movie <SENTIMENT> positive review positive review positive review positive review positive review positive review positive review positive review positive\n",
      "p(answer):  p(' positive'[3967])=0.9604, p(' negative'[4633])=0.0322, p(' I'[314])=0.0009, p(' positives'[38548])=0.0008, p(' good'[922])=0.0006\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was a bad movie <SENTIMENT> negative review negative review negative review negative review negative review negative review negative review negative review negative\n",
      "p(answer):  p(' negative'[4633])=0.9807, p(' positive'[3967])=0.0155, p(' bad'[2089])=0.0004, p(' poor'[3595])=0.0004, p(' I'[314])=0.0004\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was not a good movie <SENTIMENT> negative review negative review negative review negative review negative review negative review negative review negative review\n",
      "p(answer):  p(' negative'[4633])=0.9631, p(' positive'[3967])=0.0314, p(' I'[314])=0.0008, p(' poor'[3595])=0.0004, p(' it'[340])=0.0002\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: That movie was garbage <SENTIMENT> negative review negative review negative review negative review negative review negative review negative review negative review negative review\n",
      "p(answer):  p(' negative'[4633])=0.9222, p(' positive'[3967])=0.0708, p(' I'[314])=0.0009, p(' it'[340])=0.0004, p(' a'[257])=0.0003\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: Iphone 7 is not a good phone <SENTIMENT> positive review positive review positive review positive review positive review positive review positive review\n",
      "p(answer):  p(' positive'[3967])=0.5096, p(' negative'[4633])=0.4751, p(' I'[314])=0.0016, p(' good'[922])=0.001, p(' a'[257])=0.0007\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: Google new line of pixels are great <SENTIMENT> positive review positive review positive review positive review positive review positive review positive review positive\n",
      "p(answer):  p(' positive'[3967])=0.8594, p(' negative'[4633])=0.0956, p(' good'[922])=0.0025, p(' I'[314])=0.0023, p(' a'[257])=0.002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soft_prompts = torch.load(\"Saved_weights/Final/Prompt_Tuning/gpt2-medium/prompt_size__8.pth\", map_location='cuda:0')\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    get_answer_tokens=True,\n",
    "    light_weight_tuning= soft_prompts, algo = \"prompt\"\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefix-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_embeddings = torch.load(\"Saved_weights/Final/Prefix_Tuning/gpt2-medium/prefix_size__2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><REVIEW>: This was an awesome movie <SENTIMENT> positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.9777, p(' negative'[4633])=0.0212, p(' great'[1049])=0.0001, p(' good'[922])=0.0001, p('positive'[24561])=0.0\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><REVIEW>: This was a bad movie <SENTIMENT> negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.9861, p(' positive'[3967])=0.0133, p(' bad'[2089])=0.0001, p(' negatives'[42510])=0.0001, p(' Negative'[36183])=0.0\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><REVIEW>: This was not a good movie <SENTIMENT> negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.9454, p(' positive'[3967])=0.0543, p(' negatives'[42510])=0.0001, p('negative'[31591])=0.0, p(' negativity'[45074])=0.0\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><REVIEW>: That movie was garbage <SENTIMENT> negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.9394, p(' positive'[3967])=0.0586, p(' negativity'[45074])=0.0001, p(' Negative'[36183])=0.0001, p(' negatives'[42510])=0.0001\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><REVIEW>: Iphone 7 is not a good phone <SENTIMENT> positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.6168, p(' negative'[4633])=0.3802, p(' good'[922])=0.0004, p(' negatives'[42510])=0.0002, p(' bad'[2089])=0.0001\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><REVIEW>: Google new line of pixels are great <SENTIMENT> positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.6134, p(' negative'[4633])=0.383, p(' negatives'[42510])=0.0008, p(' positives'[38548])=0.0002, p(' good'[922])=0.0002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    get_answer_tokens=True,\n",
    "    light_weight_tuning= prefix_embeddings, algo = \"prefix\"\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, ReLU, Sequential, Tanh\n",
    "\n",
    "def init_weights(m, lo = -0.0001, hi = 0.0001):\n",
    "    if isinstance(m, Linear):\n",
    "        torch.nn.init.uniform_(m.weight, a = lo, b = hi)\n",
    "        torch.nn.init.uniform_(m.bias, a = lo, b = hi)\n",
    "\n",
    "\n",
    "class Adapter(torch.nn.Module):\n",
    "    def __init__(self, inp_out_dim, adapter_dim, hidden_conf = []):\n",
    "        super().__init__()\n",
    "        self.inp_out_dim = inp_out_dim\n",
    "        self.conf = [inp_out_dim] + hidden_conf + [adapter_dim] + hidden_conf[::-1] + [inp_out_dim]\n",
    "        # print(self.conf)\n",
    "        self.adapter_dim = adapter_dim\n",
    "        self.layers = []\n",
    "\n",
    "        i = 1\n",
    "        while i < len(self.conf):\n",
    "            inp = self.conf[i-1]\n",
    "            out = self.conf[i]\n",
    "            layer_name = f'layer{i}'\n",
    "            setattr(self, layer_name, Sequential(Linear(inp, out), ReLU()))\n",
    "            self.layers.append(layer_name)\n",
    "            i += 1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_init = x.clone()\n",
    "        for module in self.named_children():\n",
    "            layer_name = module[0]\n",
    "            layer = getattr(self, layer_name)\n",
    "            x = layer(x)\n",
    "        return x + x_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_blocks = torch.load(\"Saved_weights/Final/Adapters/gpt2-medium/adapter_dim__32.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<REVIEW>: This was an awesome movie <SENTIMENT> positive. I was blown away by the way the cast and crew handled the situation. I was also blown away by the way\n",
      "p(answer):  p(' positive'[3967])=0.7549, p(' awesome'[7427])=0.114, p(' great'[1049])=0.0158, p(' amazing'[4998])=0.0147, p(' good'[922])=0.0062\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<REVIEW>: This was a bad movie <SENTIMENT> negative. I don't know what the hell I was thinking. I was so disappointed. I was so disappointed that I was\n",
      "p(answer):  p(' negative'[4633])=0.7905, p(' bad'[2089])=0.0838, p(' positive'[3967])=0.0202, p(' terrible'[7818])=0.0091, p(' BAD'[33934])=0.0067\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<REVIEW>: This was not a good movie <SENTIMENT> negative. I was not impressed with the story, the acting, the direction, the acting, the direction, the acting\n",
      "p(answer):  p(' negative'[4633])=0.8288, p(' positive'[3967])=0.0465, p(' bad'[2089])=0.0125, p(' not'[407])=0.006, p(' of'[286])=0.0038\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<REVIEW>: That movie was garbage <SENTIMENT> negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.9949, p(' positive'[3967])=0.005, p(' bad'[2089])=0.0, p(' Negative'[36183])=0.0, p(' garbage'[15413])=0.0\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>  I have a phone that is not a good phone. I have a phone that is not a good\n",
      "p(answer):  p('\n",
      "'[198])=0.1249, p(' I'[314])=0.0611, p(' negative'[4633])=0.053, p(' positive'[3967])=0.0448, p(' but'[475])=0.0233\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT> negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.1453, p(' positive'[3967])=0.1232, p('\n",
      "'[198])=0.0841, p(' I'[314])=0.0167, p(' <'[1279])=0.0131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    get_answer_tokens=True,\n",
    "    light_weight_tuning= adapter_blocks, algo = \"adapter\"\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Model gpt2-medium initialized\n"
     ]
    }
   ],
   "source": [
    "mt_2 = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=False)\n",
    "model_2 = mt_2.model\n",
    "tokenizer_2 = mt_2.tokenizer\n",
    "tokenizer_2.pad_token = tokenizer_2.eos_token\n",
    "print(f\"Duplicate Model {MODEL_NAME} initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint\n",
      "loaded model weights\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"Saved_weights/Final/Finetune/gpt2-medium/gpt2-medium____data_40000.pth\")\n",
    "print(\"loaded checkpoint\")\n",
    "model_2.load_state_dict(checkpoint)\n",
    "print(\"loaded model weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<REVIEW>: This was an awesome movie <SENTIMENT> positive negative negative negative negative negative negative negative negative negative positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.9651, p(' negative'[4633])=0.0349, p(' Positive'[33733])=0.0, p(' positives'[38548])=0.0, p('positive'[24561])=0.0\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<REVIEW>: This was a bad movie <SENTIMENT> negative positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' negative'[4633])=0.849, p(' positive'[3967])=0.151, p(' Negative'[36183])=0.0, p(' Positive'[33733])=0.0, p(' positives'[38548])=0.0\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<REVIEW>: This was not a good movie <SENTIMENT> positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive negative\n",
      "p(answer):  p(' positive'[3967])=0.7583, p(' negative'[4633])=0.2417, p(' Positive'[33733])=0.0, p(' positives'[38548])=0.0, p('positive'[24561])=0.0\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<REVIEW>: That movie was garbage <SENTIMENT> negative positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' negative'[4633])=0.9728, p(' positive'[3967])=0.0272, p(' Negative'[36183])=0.0, p(' negatives'[42510])=0.0, p('negative'[31591])=0.0\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT> negative negative positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' negative'[4633])=0.5689, p(' positive'[3967])=0.4311, p(' Positive'[33733])=0.0, p(' positives'[38548])=0.0, p(' Negative'[36183])=0.0\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT> positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.8059, p(' negative'[4633])=0.1941, p(' Positive'[33733])=0.0, p(' positives'[38548])=0.0, p('positive'[24561])=0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model_2, tokenizer_2,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rome')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3835239043501baad7b502b0573c70a3454f6c2753902e68361683a11a30d10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
