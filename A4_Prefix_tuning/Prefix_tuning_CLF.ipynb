{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import nethook\n",
    "from utils import model_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-medium\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=False)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple has recently released their iPhone 14 line of\n",
      "Apple has recently released their iPhone 14 line of smartphones and they have introduced the Apple Watch Series 4. Apple has also introduced the iPhone 8 series of smartphones and they have introduced the iPhone X series. These two new smartphones have been released by different companies.\n",
      "p(answer):  p(' devices'[4410])=0.2049, p(' phones'[9512])=0.1882, p(' smartphones'[18151])=0.1707, p(' hands'[2832])=0.0887, p(' products'[3186])=0.0367\n",
      "\n",
      "Goole has released Pixel 7\n",
      "Goole has released Pixel 7, a new flagship handset from Google that has been praised by many as one of its biggest devices to date. The Pixel 7 is a 5.5-inch Android phone, sporting a 5.5-inch display\n",
      "p(answer):  p(' and'[290])=0.1817, p(','[11])=0.0804, p('.'[13])=0.0659, p(' Plus'[8227])=0.0247, p(' on'[319])=0.0194\n",
      "\n",
      "I am taking a Machine Learning class\n",
      "I am taking a Machine Learning class and I am learning how to build a model of a human body. I have a few questions that are related to how to model the human body.  What are the best models for the body?  \n",
      "p(answer):  p(' at'[379])=0.198, p(' in'[287])=0.0797, p(' with'[351])=0.071, p('.'[13])=0.0633, p(' and'[290])=0.0631\n",
      "\n",
      "Eiffel Tower is in Paris.\n",
      "Eiffel Tower is in Paris. The city of Paris and the French capital are both in France and are home to a lot of people, but they have their own distinct cultures and customs. The French capital is also the capital of France, the\n",
      "p(answer):  p('\n",
      "'[198])=0.2083, p(' The'[383])=0.1101, p(' It'[632])=0.075, p(' In'[554])=0.0222, p(' I'[314])=0.0214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    \"Apple has recently released their iPhone 14 line of\",\n",
    "    \"Goole has released Pixel 7\",\n",
    "    \"I am taking a Machine Learning class\",\n",
    "    \"Eiffel Tower is in Paris.\"\n",
    "]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = False,\n",
    "    max_out_len= 50,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset (the `IMDB_50K_Reviews` dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38747</th>\n",
       "      <td>.... could it be that ITV wouldn't want to rel...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32984</th>\n",
       "      <td>A typical Lanza flick that had limited audienc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>Kurt Thomas stars as Jonathan Cabot some kind ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32170</th>\n",
       "      <td>It's a gentle, easy-going 1950s comedy. Kim No...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21268</th>\n",
       "      <td>As you may have gathered from the title, I who...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "38747  .... could it be that ITV wouldn't want to rel...  positive\n",
       "32984  A typical Lanza flick that had limited audienc...  negative\n",
       "10374  Kurt Thomas stars as Jonathan Cabot some kind ...  negative\n",
       "32170  It's a gentle, easy-going 1950s comedy. Kim No...  positive\n",
       "21268  As you may have gathered from the title, I who...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/IMDB_50K_Reviews/archive/IMDB Dataset.csv\")\n",
    "df = df.sample(frac = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... could it be that ITV wouldn't want to release this absolute classic because it would show up their current series of Mike Bassett for what it is? When discussing Mike Bassett with some work colleagues I mentioned Bostock's Cup as being a far superior offering and was surprised to find that I seem to be the only person in my entire office that has actually seen it. This can't be right for a film that has got to be the funniest thing I have ever seen.<br /><br />Let's face it, ITV don't have the greatest recent record for producing comedy so you would think that they would jump at the chance of at least repeating something which is genuinely funny. Perhaps if it could be combined with a lucrative telephone competition of where we think the coach driver will go next then they might be interested.<br /><br />Come on ITV, there are still some of us out there who would like to watch original, quality comedy/drama. Do the decent thing thing. Repeat it then get it out on DVD.\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row[\"review\"])\n",
    "    print(row[\"sentiment\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[0:30000]\n",
    "validation_df = df[30000:40000]\n",
    "test_df = df[40000:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 2), (10000, 2), (10000, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, validation_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load presaved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../Data/IMDB_50K_Reviews/train.csv\")\n",
    "validation_df = pd.read_csv(\"../Data/IMDB_50K_Reviews/validation.csv\")\n",
    "test_df = pd.read_csv(\"../Data/IMDB_50K_Reviews/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import re\n",
    "CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});|/.*/')\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  raw_html = raw_html.replace(\"\\\\\", \"\")\n",
    "  raw_html = raw_html.replace(\"&#039;\", \"\\'\")\n",
    "  cleantext = re.sub(CLEANR, ' ', raw_html)\n",
    "  split = cleantext.strip().split(\" \")\n",
    "  if(split[0].isnumeric()):\n",
    "    split = split[1:]\n",
    "  return \" \".join([w for w in split if len(w.strip()) > 0])\n",
    "\n",
    "# cleanhtml(\"Don&#039;t mess with me\")\n",
    "# cleanhtml('<a href=\"#p79290593\" class=\"quotelink\">&gt;&gt;79290593</a><br><span class=\"quote\">&gt;canada</span><br><br>and you faggots think we&#039;re the worst shit posters')\n",
    "\n",
    "class GoEmotions(Dataset):\n",
    "    def __init__(self, data_frame):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "\n",
    "        for index, row in data_frame.iterrows():\n",
    "            self.x.append(\"<REVIEW>: \" + cleanhtml(row[\"review\"]) + \" <SENTIMENT>\")\n",
    "            self.y.append(\" \" + row[\"sentiment\"])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 10000, 10000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = GoEmotions(train_df)\n",
    "validation_dataset = GoEmotions(validation_df)\n",
    "test_dataset = GoEmotions(test_df)\n",
    "\n",
    "len(training_dataset), len(validation_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "testing_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = \"transformer.wte\"\n",
    "layer_norm_final = \"transformer.ln_f\"\n",
    "transformer_blocks = [f\"transformer.h.{n}\" for n in range(model.config.n_layer)]\n",
    "unembedder = \"lm_head\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "prefix_size = 10\n",
    "num_epochs = 10\n",
    "###############################################################################################################\n",
    "\n",
    "learning_rate = 5e-4\n",
    "warmup_steps = 200\n",
    "weight_decay = 0\n",
    "\n",
    "optimization_batch_size = 8\n",
    "max_token_per_comment = 963\n",
    "\n",
    "save_path = f\"../Saved_weights/Prefix-Tuned_CLF__IMDB_50K/{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_module = nethook.get_module(model, embedder)\n",
    "lm_head = nethook.get_module(model, unembedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 1024])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "init_words = [\"sentiment\", \"elephant\", \"review\"]\n",
    "def get_initial_prefix(prefix_size = 5):\n",
    "    words = random.choices(init_words, k=prefix_size)\n",
    "    sentence = \" \" + \" \".join(words)\n",
    "    tokenized = tokenizer(sentence, return_tensors = \"pt\").to(next(model.parameters()).device)\n",
    "    return embedder_module(tokenized['input_ids'])\n",
    "\n",
    "get_initial_prefix(7).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untuple(output):\n",
    "    if(type(output) is tuple):\n",
    "        return output[0]\n",
    "    return output\n",
    "\n",
    "def get_shape(output):\n",
    "    pre = f\"{type(output)} ==> \"\n",
    "    if(type(output) is tuple):\n",
    "        return pre + f\"{output[0].shape} -- {(output[1][0].shape, output[1][1].shape)}\"\n",
    "    return pre + f\"{output.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefix_tuning_edit(prefix_embeddings):\n",
    "    def insert_prompt_embeddings(output, layer, prefix_embeddings = prefix_embeddings):\n",
    "        if(layer not in prefix_embeddings):\n",
    "            return output\n",
    "        # print(\"intervention ==> \", layer, \"output shape ===> \", get_shape(output))\n",
    "        # return output\n",
    "        X = untuple(output)\n",
    "        prefix_now = prefix_embeddings[layer]\n",
    "        prefix_size = prefix_now.shape[1]\n",
    "        arr = []\n",
    "        for batch in X:\n",
    "            added = torch.cat((prefix_now[0], batch[prefix_size:, :]))\n",
    "            arr.append(added)\n",
    "        X = torch.stack(arr)\n",
    "\n",
    "        if(type(output) is not tuple):\n",
    "            return X\n",
    "        else:\n",
    "            return (X, output[1])\n",
    "    return insert_prompt_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 1024])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "prefix_embeddings = {\n",
    "    key: get_initial_prefix(prefix_size) for key in [embedder] + transformer_blocks[:-1]\n",
    "}\n",
    "\n",
    "prefix_embeddings[embedder].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = [\n",
    "#     \"Apple has recently released their iPhone 14 line of\",\n",
    "#     \"Goole has released Pixel 7\",\n",
    "#     \"I am taking a Machine Learning class\",\n",
    "#     \"Eiffel Tower is in Paris.\"\n",
    "# ]\n",
    "\n",
    "# txt, ret_dict = model_utils.generate_fast(\n",
    "#     model, tokenizer,\n",
    "#     prompt,\n",
    "#     argmax_greedy = False,\n",
    "#     max_out_len= 50,\n",
    "#     # debug=True,\n",
    "#     get_answer_tokens=True,\n",
    "\n",
    "#     light_weight_tuning=prefix_embeddings, algo = \"prefix\"\n",
    "# )\n",
    "\n",
    "# model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/15000 [00:00<14:32, 17.20it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "  5%|▍         | 720/15000 [01:25<28:17,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################  CHECKPOINT -- saving weights #####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# optimizer = AdamW(\n",
    "#     # model.parameters(),\n",
    "#     [v for _, v in tunable_weights.items()],\n",
    "#     lr = learning_rate,\n",
    "# )\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
    "# )\n",
    "\n",
    "for k in prefix_embeddings:\n",
    "    prefix_embeddings[k].requires_grad = True\n",
    "\n",
    "for name, w in model.named_parameters():\n",
    "    w.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [prefix_embeddings[k] for k in prefix_embeddings],\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    ")\n",
    "\n",
    "num_prompts_optimized = 0\n",
    "training_loss_track = []\n",
    "validation_loss_track = []\n",
    "\n",
    "target_track = {\n",
    "    \" positive\": 0,\n",
    "    \" negative\": 0\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "insert_prefix_embeddings = get_prefix_tuning_edit(prefix_embeddings)\n",
    "###############################################################################\n",
    "\n",
    "limit = 700\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    for reviews, sentiments in tqdm(training_dataloader):\n",
    "        tokenized_inputs = tokenizer(\n",
    "            list(reviews),\n",
    "            padding = True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(next(model.parameters()).device)\n",
    "\n",
    "        # add soft tokens\n",
    "        prefix_tokens = torch.ones(len(reviews), prefix_size, dtype = int).to(next(model.parameters()).device) * model.config.bos_token_id\n",
    "        tokenized_inputs[\"input_ids\"] = torch.cat((prefix_tokens, tokenized_inputs[\"input_ids\"]), dim = 1)\n",
    "        prefix_attn = torch.ones(len(reviews), prefix_size, dtype = int).to(next(model.parameters()).device)\n",
    "        tokenized_inputs[\"attention_mask\"] = torch.cat((prefix_attn, tokenized_inputs[\"attention_mask\"]), dim = 1)\n",
    "\n",
    "        if(tokenized_inputs['input_ids'].shape[1] > max_token_per_comment):\n",
    "            # print(f\"BLOCKED ==> {tokenized_inputs['input_ids'].shape[1]}\")\n",
    "            continue\n",
    "            \n",
    "        for t in sentiments:\n",
    "            target_track[t] += 1\n",
    "\n",
    "        target_ids = tokenizer(\n",
    "            list(sentiments), \n",
    "            padding = True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(next(model.parameters()).device)['input_ids']\n",
    "\n",
    "        # print(sentiments)\n",
    "\n",
    "        # print(tokenized_inputs['input_ids'].shape)\n",
    "        # print(sentiments, target_ids)\n",
    "\n",
    "        last_token_inds = tokenized_inputs[\"attention_mask\"].sum(dim=1) - 1\n",
    "        loss_mask = target_ids != tokenizer.unk_token_id\n",
    "\n",
    "        # tokenized[\"input_ids\"].require_grad = True\n",
    "        with nethook.TraceDict(\n",
    "            model,\n",
    "            [embedder, layer_norm_final, unembedder],\n",
    "            edit_output=insert_prefix_embeddings\n",
    "        ) as traces:\n",
    "            outputs = model(\n",
    "                **tokenized_inputs, \n",
    "                labels=tokenized_inputs['input_ids']\n",
    "            )\n",
    "\n",
    "        probs = torch.nn.functional.log_softmax(\n",
    "            outputs.logits[torch.arange(batch_size), last_token_inds], dim=-1\n",
    "        )\n",
    "        # print(probs)\n",
    "\n",
    "        loss = -(torch.gather(probs, 1, target_ids) * loss_mask).sum(1) / loss_mask.sum(1)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        training_loss_track.append(loss.item())\n",
    "        # print(loss)\n",
    "\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        limit -= 1\n",
    "        if(limit == 0):\n",
    "            break\n",
    "        \n",
    "    print(\"#####################  CHECKPOINT -- saving weights #####################\")\n",
    "    os.makedirs(save_path, exist_ok = True)\n",
    "    torch.save(prefix_embeddings, f\"{save_path}/prefixtuned__epoch_{epoch+1}.pth\")\n",
    "    with open(f\"{save_path}/loss_track_{epoch + 1}.json\", \"w\") as f:\n",
    "        json.dump({\"training\": training_loss_track, \"validation\": validation_loss_track}, f)\n",
    "    \n",
    "    plt.title(\"\")\n",
    "    plt.plot(training_loss_track)\n",
    "    plt.show()\n",
    "    training_loss_track = []\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('../Saved_weights/Fine-Tuned_CLF__IMDB_50K/gpt2-medium/finetuned_0.pth')\n",
    "# model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was an awesome movie <SENTIMENT> positive positive negative negative negative negative positive positive positive negative negative negative negative negative negative\n",
      "p(answer):  p(' positive'[3967])=0.9034, p(' negative'[4633])=0.0607, p(' review'[2423])=0.0154, p(','[11])=0.0015, p('positive'[24561])=0.0014\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was a bad movie <SENTIMENT> positive positive negative negative negative negative positive positive negative negative negative negative negative negative negative\n",
      "p(answer):  p(' positive'[3967])=0.5976, p(' negative'[4633])=0.36, p(' review'[2423])=0.0193, p(','[11])=0.0017, p('positive'[24561])=0.0009\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was not a good movie <SENTIMENT> positive positive negative negative negative negative positive positive negative negative negative negative negative negative\n",
      "p(answer):  p(' positive'[3967])=0.7039, p(' negative'[4633])=0.2677, p(' review'[2423])=0.0121, p('positive'[24561])=0.0012, p(','[11])=0.001\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: That movie was garbage <SENTIMENT> positive positive negative negative negative negative positive positive negative negative negative negative negative negative negative negative\n",
      "p(answer):  p(' positive'[3967])=0.684, p(' negative'[4633])=0.2765, p(' review'[2423])=0.0174, p(','[11])=0.0014, p(' quality'[3081])=0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    \"This was an awesome movie\",\n",
    "    \"This was a bad movie\",\n",
    "    \"This was not a good movie\",\n",
    "    \"That movie was garbage\"\n",
    "]\n",
    "\n",
    "prompt = [\"<REVIEW>: \" + p + \" <SENTIMENT>\" for p in prompt]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    "\n",
    "    light_weight_tuning= prefix_embeddings, algo = \"prefix\"\n",
    "    # track_interesting_words = [\n",
    "    #     [\" positive\", \" negative\"],\n",
    "    #     [\" positive\", \" negative\"]\n",
    "    # ]\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [00:28<3:10:50,  5.74s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb Cell 30\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m max_out_len \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(last_token_inds)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     txt, ret_dict \u001b[39m=\u001b[39m model_utils\u001b[39m.\u001b[39;49mgenerate_fast(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         model, tokenizer,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mlist\u001b[39;49m(reviews),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         argmax_greedy \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         max_out_len\u001b[39m=\u001b[39;49m max_out_len \u001b[39m+\u001b[39;49m prefix_size \u001b[39m+\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         \u001b[39m# debug=True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         get_answer_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         light_weight_tuning\u001b[39m=\u001b[39;49m prefix_embeddings, algo \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mprefix\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m t, p \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mlist\u001b[39m(sentiment), ret_dict[\u001b[39m'\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/local_arnab/Codes/EmoGPT/A4_Prefix_tuning/Prefix_tuning_CLF.ipynb#X36sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     target\u001b[39m.\u001b[39mappend(t)\n",
      "File \u001b[0;32m~/Codes/EmoGPT/A4_Prefix_tuning/../utils/model_utils.py:185\u001b[0m, in \u001b[0;36mgenerate_fast\u001b[0;34m(model, tok, prompts, top_k, max_out_len, argmax_greedy, debug, get_answer_tokens, track_interesting_words, light_weight_tuning, algo, embedder)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mwhile\u001b[39;00m input_ids\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m) \u001b[39m<\u001b[39m max_out_len:  \u001b[39m# while not exceeding max output length\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39mwith\u001b[39;00m nethook\u001b[39m.\u001b[39mTraceDict(\n\u001b[1;32m    183\u001b[0m         model, [embedder], edit_output\u001b[39m=\u001b[39m intervention_function\n\u001b[1;32m    184\u001b[0m     ) \u001b[39mas\u001b[39;00m traces:\n\u001b[0;32m--> 185\u001b[0m         model_out \u001b[39m=\u001b[39m model(\n\u001b[1;32m    186\u001b[0m             input_ids\u001b[39m=\u001b[39;49minput_ids[:, cur_context],\n\u001b[1;32m    187\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mattention_mask[:, cur_context],\n\u001b[1;32m    188\u001b[0m             past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    189\u001b[0m             use_cache\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    190\u001b[0m         )\n\u001b[1;32m    191\u001b[0m     \u001b[39mif\u001b[39;00m(intervention_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    192\u001b[0m         intervention_function \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rome/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rome/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:1044\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m    `-100` are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1044\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m   1045\u001b[0m     input_ids,\n\u001b[1;32m   1046\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1047\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1048\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1049\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1050\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1051\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1052\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1053\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1054\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1055\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1056\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1057\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1058\u001b[0m )\n\u001b[1;32m   1059\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1061\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rome/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rome/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:887\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    877\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    878\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    879\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    884\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    885\u001b[0m     )\n\u001b[1;32m    886\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 887\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[1;32m    888\u001b[0m         hidden_states,\n\u001b[1;32m    889\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    890\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    891\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m    892\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    893\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    894\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    895\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    896\u001b[0m     )\n\u001b[1;32m    898\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    899\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rome/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rome/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:395\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    393\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    394\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 395\u001b[0m attn_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[1;32m    396\u001b[0m     hidden_states,\n\u001b[1;32m    397\u001b[0m     layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    398\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    399\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    400\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    401\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    402\u001b[0m )\n\u001b[1;32m    403\u001b[0m attn_output \u001b[39m=\u001b[39m attn_outputs[\u001b[39m0\u001b[39m]  \u001b[39m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    404\u001b[0m outputs \u001b[39m=\u001b[39m attn_outputs[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/rome/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rome/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:336\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    334\u001b[0m     attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attn(query, key, value, attention_mask, head_mask)\n\u001b[1;32m    338\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_heads(attn_output, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\n\u001b[1;32m    339\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_proj(attn_output)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "testing_dataloader = DataLoader(test_dataset, batch_size=5)\n",
    "\n",
    "target = []\n",
    "predict = []\n",
    "\n",
    "for reviews, sentiment in tqdm(testing_dataloader):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        list(reviews),\n",
    "        padding = True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(next(model.parameters()).device)\n",
    "\n",
    "    if(tokenized_inputs['input_ids'].shape[1] > max_token_per_comment):\n",
    "        # print(f\"BLOCKED ==> {tokenized_inputs['input_ids'].shape[1]}\")\n",
    "        continue\n",
    "\n",
    "    last_token_inds = tokenized_inputs[\"attention_mask\"].sum(dim=1)\n",
    "    max_out_len = max(last_token_inds).item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        txt, ret_dict = model_utils.generate_fast(\n",
    "            model, tokenizer,\n",
    "            list(reviews),\n",
    "            argmax_greedy = True,\n",
    "            max_out_len= max_out_len + prefix_size + 3,\n",
    "            # debug=True,\n",
    "            get_answer_tokens=True,\n",
    "\n",
    "            light_weight_tuning= prefix_embeddings, algo = \"prefix\"\n",
    "        )\n",
    "\n",
    "    for t, p in zip(list(sentiment), ret_dict['answer']):\n",
    "        target.append(t)\n",
    "        predict.append(p['top_token'])\n",
    "\n",
    "    # print(txt, ret_dict['answer'])\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 1\n",
      "1 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(target, predict).ravel()\n",
    "\n",
    "print(tp, fp)\n",
    "print(fn, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9198717948717949"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity = tp/(tp + fn)\n",
    "specificity = tn/(tn + fp)\n",
    "balanced_acc = (sensitivity + specificity)/2\n",
    "\n",
    "balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3835239043501baad7b502b0573c70a3454f6c2753902e68361683a11a30d10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
