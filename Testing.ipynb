{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import nethook\n",
    "from utils import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-medium\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=False)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<REVIEW>: This was an awesome movie <SENTIMENT> <REVIEW>: I love this movie <REVIEW>: I love this movie <REVIEW>: I love this movie <\n",
      "p(answer):  p(' <'[1279])=0.0664, p('\n",
      "'[198])=0.0569, p(' :'[1058])=0.05, p(' I'[314])=0.0458, p(' It'[632])=0.0208\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<REVIEW>: This was a bad movie <SENTIMENT> <REVIEW>: I don't know what to say <REVIEW>: I'm not sure what to say <REVIEW\n",
      "p(answer):  p(' <'[1279])=0.0586, p(' :'[1058])=0.0528, p('\n",
      "'[198])=0.0445, p(' I'[314])=0.0341, p(' ('[357])=0.0278\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<REVIEW>: This was not a good movie <SENTIMENT> <REVIEW>: I don't think it was a good movie <REVIEW>: I think it was a good movie\n",
      "p(answer):  p(' <'[1279])=0.0508, p(' :'[1058])=0.0455, p(' I'[314])=0.0397, p('\n",
      "'[198])=0.0332, p(' ('[357])=0.0229\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<REVIEW>: That movie was garbage <SENTIMENT> <REVIEW>: I'm not going to watch it <REVIEW>: I'm not going to watch it <REVIEW>:\n",
      "p(answer):  p(' <'[1279])=0.0796, p('\n",
      "'[198])=0.0445, p(' ['[685])=0.0359, p(' :'[1058])=0.0331, p(' I'[314])=0.0305\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT> <REVIEW>: Iphone 7 is not a good phone <SENTIMENT> <REVIEW>:\n",
      "p(answer):  p(' <'[1279])=0.055, p(' I'[314])=0.0377, p(' :'[1058])=0.0246, p('\n",
      "'[198])=0.0221, p(' http'[2638])=0.022\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT> <REVIEW>: I'm not sure if this is a bug or a feature <REVIEW>: I'm not\n",
      "p(answer):  p(' <'[1279])=0.0745, p('\n",
      "'[198])=0.0385, p(' :'[1058])=0.0319, p(' ['[685])=0.0252, p(' http'[2638])=0.0225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    \"This was an awesome movie\",\n",
    "    \"This was a bad movie\",\n",
    "    \"This was not a good movie\",\n",
    "    \"That movie was garbage\",\n",
    "    \"Iphone 7 is not a good phone\",\n",
    "    \"Google new line of pixels are great\"\n",
    "]\n",
    "\n",
    "prompt = [\"<REVIEW>: \" + p + \" <SENTIMENT>\" for p in prompt]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    "\n",
    "    # track_interesting_words = [\n",
    "    #     [\" positive\", \" negative\"],\n",
    "    #     [\" positive\", \" negative\"]\n",
    "    # ]\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint\n",
      "loaded model weights\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('Saved_weights/Fine-Tuned_CLF__IMDB_50K/gpt2-medium/finetuned__epoch_2.pth')\n",
    "print(\"loaded checkpoint\")\n",
    "model.load_state_dict(checkpoint)\n",
    "print(\"loaded model weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<REVIEW>: This was an awesome movie <SENTIMENT> positive positive negative positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.9382, p(' negative'[4633])=0.0617, p(' Positive'[33733])=0.0, p(' positives'[38548])=0.0, p('positive'[24561])=0.0\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<REVIEW>: This was a bad movie <SENTIMENT> negative positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' negative'[4633])=0.8916, p(' positive'[3967])=0.1082, p(' Negative'[36183])=0.0, p(' negatives'[42510])=0.0, p(' Positive'[33733])=0.0\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<REVIEW>: This was not a good movie <SENTIMENT> positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.738, p(' negative'[4633])=0.2619, p(' Positive'[33733])=0.0, p(' positives'[38548])=0.0, p('positive'[24561])=0.0\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<REVIEW>: That movie was garbage <SENTIMENT> negative positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' negative'[4633])=0.9724, p(' positive'[3967])=0.0275, p(' Negative'[36183])=0.0, p(' negatives'[42510])=0.0, p('negative'[31591])=0.0\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT> positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.5648, p(' negative'[4633])=0.435, p(' Positive'[33733])=0.0, p(' positives'[38548])=0.0, p(' Negative'[36183])=0.0\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT> positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.6838, p(' negative'[4633])=0.316, p(' Positive'[33733])=0.0, p(' positives'[38548])=0.0, p('positive'[24561])=0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    \"This was an awesome movie\",\n",
    "    \"This was a bad movie\",\n",
    "    \"This was not a good movie\",\n",
    "    \"That movie was garbage\",\n",
    "    \"Iphone 7 is not a good phone\",\n",
    "    \"Google new line of pixels are great\"\n",
    "]\n",
    "\n",
    "prompt = [\"<REVIEW>: \" + p + \" <SENTIMENT>\" for p in prompt]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    "\n",
    "    # track_interesting_words = [\n",
    "    #     [\" positive\", \" negative\"],\n",
    "    #     [\" positive\", \" negative\"]\n",
    "    # ]\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rome')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3835239043501baad7b502b0573c70a3454f6c2753902e68361683a11a30d10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
