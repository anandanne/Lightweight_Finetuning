{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import nethook\n",
    "from utils import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-medium\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=False)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<REVIEW>: This was an awesome movie <SENTIMENT> <REVIEW>: I love this movie <REVIEW>: I love this movie <REVIEW>: I love this movie <\n",
      "p(answer):  p(' <'[1279])=0.0664, p('\n",
      "'[198])=0.0569, p(' :'[1058])=0.05, p(' I'[314])=0.0458, p(' It'[632])=0.0208\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<REVIEW>: This was a bad movie <SENTIMENT> <REVIEW>: I don't know what to say <REVIEW>: I'm not sure what to say <REVIEW\n",
      "p(answer):  p(' <'[1279])=0.0586, p(' :'[1058])=0.0528, p('\n",
      "'[198])=0.0445, p(' I'[314])=0.0341, p(' ('[357])=0.0278\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<REVIEW>: This was not a good movie <SENTIMENT> <REVIEW>: I don't think it was a good movie <REVIEW>: I think it was a good movie\n",
      "p(answer):  p(' <'[1279])=0.0508, p(' :'[1058])=0.0455, p(' I'[314])=0.0397, p('\n",
      "'[198])=0.0332, p(' ('[357])=0.0229\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<REVIEW>: That movie was garbage <SENTIMENT> <REVIEW>: I'm not going to watch it <REVIEW>: I'm not going to watch it <REVIEW>:\n",
      "p(answer):  p(' <'[1279])=0.0796, p('\n",
      "'[198])=0.0445, p(' ['[685])=0.0359, p(' :'[1058])=0.0331, p(' I'[314])=0.0305\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT> <REVIEW>: Iphone 7 is not a good phone <SENTIMENT> <REVIEW>:\n",
      "p(answer):  p(' <'[1279])=0.055, p(' I'[314])=0.0377, p(' :'[1058])=0.0246, p('\n",
      "'[198])=0.0221, p(' http'[2638])=0.022\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT> <REVIEW>: I'm not sure if this is a bug or a feature <REVIEW>: I'm not\n",
      "p(answer):  p(' <'[1279])=0.0745, p('\n",
      "'[198])=0.0385, p(' :'[1058])=0.0319, p(' ['[685])=0.0252, p(' http'[2638])=0.0225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "    \"This was an awesome movie\",\n",
    "    \"This was a bad movie\",\n",
    "    \"This was not a good movie\",\n",
    "    \"That movie was garbage\",\n",
    "    \"Iphone 7 is not a good phone\",\n",
    "    \"Google new line of pixels are great\"\n",
    "]\n",
    "\n",
    "prompt = [\"<REVIEW>: \" + p + \" <SENTIMENT>\" for p in prompt]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    "\n",
    "    # track_interesting_words = [\n",
    "    #     [\" positive\", \" negative\"],\n",
    "    #     [\" positive\", \" negative\"]\n",
    "    # ]\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_prompts = torch.load(\"Saved_weights/Promt-Tuned_CLF__IMDB_50K/gpt2-medium/promptuned__epoch_10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was an awesome movie <SENTIMENT> positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.995, p(' negative'[4633])=0.0049, p(' positively'[19888])=0.0, p(' positives'[38548])=0.0, p(' good'[922])=0.0\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was a bad movie <SENTIMENT> negative, negative, negative\n",
      "p(answer):  p(' negative'[4633])=0.9986, p(' positive'[3967])=0.0014, p(' derogatory'[44094])=0.0, p(' bad'[2089])=0.0, p(' critical'[4688])=0.0\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was not a good movie <SENTIMENT> negative positive positive positive\n",
      "p(answer):  p(' negative'[4633])=0.996, p(' positive'[3967])=0.004, p(' critical'[4688])=0.0, p(' pro'[386])=0.0, p(' unfavorable'[38206])=0.0\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: That movie was garbage <SENTIMENT> negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.9967, p(' positive'[3967])=0.0033, p(' pro'[386])=0.0, p(' negativity'[45074])=0.0, p(' derogatory'[44094])=0.0\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: Iphone 7 is not a good phone <SENTIMENT> negative positive\n",
      "p(answer):  p(' negative'[4633])=0.9848, p(' positive'[3967])=0.0151, p(' Negative'[36183])=0.0, p(' pro'[386])=0.0, p(' negativity'[45074])=0.0\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: Google new line of pixels are great <SENTIMENT> positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.8062, p(' negative'[4633])=0.1937, p(' Positive'[33733])=0.0, p(' negatives'[42510])=0.0, p(' positives'[38548])=0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    get_answer_tokens=True,\n",
    "    light_weight_tuning= soft_prompts, algo = \"prompt\"\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefix-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_embeddings = torch.load('Saved_weights/Prefix-Tuned_CLF__IMDB_50K/gpt2-medium/prefixtuned__epoch_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was an awesome movie <SENTIMENT> positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.9853, p(' negative'[4633])=0.0146, p('positive'[24561])=0.0, p(' Positive'[33733])=0.0, p(' favorable'[17070])=0.0\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was a bad movie <SENTIMENT> negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.9859, p(' positive'[3967])=0.014, p('negative'[31591])=0.0, p(' Negative'[36183])=0.0, p(' negatively'[22533])=0.0\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: This was not a good movie <SENTIMENT> negative negative negative negative negative negative negative negative negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.9011, p(' positive'[3967])=0.0986, p('negative'[31591])=0.0, p(' Negative'[36183])=0.0, p('positive'[24561])=0.0\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: That movie was garbage <SENTIMENT> negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.9864, p(' positive'[3967])=0.0134, p(' Negative'[36183])=0.0, p('negative'[31591])=0.0, p(' negatively'[22533])=0.0\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: Iphone 7 is not a good phone <SENTIMENT> negative negative negative negative negative negative negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.8875, p(' positive'[3967])=0.112, p('negative'[31591])=0.0001, p(' Negative'[36183])=0.0, p('positive'[24561])=0.0\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><REVIEW>: Google new line of pixels are great <SENTIMENT> positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.9154, p(' negative'[4633])=0.0843, p('positive'[24561])=0.0001, p(' Positive'[33733])=0.0, p(' favorable'[17070])=0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    get_answer_tokens=True,\n",
    "    light_weight_tuning= prefix_embeddings, algo = \"prefix\"\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, ReLU, Sequential, Tanh\n",
    "\n",
    "def init_weights(m, lo = -0.0001, hi = 0.0001):\n",
    "    if isinstance(m, Linear):\n",
    "        torch.nn.init.uniform_(m.weight, a = lo, b = hi)\n",
    "        torch.nn.init.uniform_(m.bias, a = lo, b = hi)\n",
    "\n",
    "\n",
    "class Adapter(torch.nn.Module):\n",
    "    def __init__(self, inp_out_dim, adapter_dim, hidden_conf = []):\n",
    "        super().__init__()\n",
    "        self.inp_out_dim = inp_out_dim\n",
    "        self.conf = [inp_out_dim] + hidden_conf + [adapter_dim] + hidden_conf[::-1] + [inp_out_dim]\n",
    "        # print(self.conf)\n",
    "        self.adapter_dim = adapter_dim\n",
    "        self.layers = []\n",
    "\n",
    "        i = 1\n",
    "        while i < len(self.conf):\n",
    "            inp = self.conf[i-1]\n",
    "            out = self.conf[i]\n",
    "            layer_name = f'layer{i}'\n",
    "            setattr(self, layer_name, Sequential(Linear(inp, out), ReLU()))\n",
    "            self.layers.append(layer_name)\n",
    "            i += 1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_init = x.clone()\n",
    "        for module in self.named_children():\n",
    "            layer_name = module[0]\n",
    "            layer = getattr(self, layer_name)\n",
    "            x = layer(x)\n",
    "        return x + x_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_blocks = torch.load(\"Saved_weights/Adapter-Tuned_CLF__IMDB_50K/gpt2-medium/adapter_tuned__epoch_3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<REVIEW>: This was an awesome movie <SENTIMENT>\n",
      "<REVIEW>: This was an awesome movie <SENTIMENT> positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive positive\n",
      "p(answer):  p(' positive'[3967])=0.5254, p(' awesome'[7427])=0.046, p(' of'[286])=0.0219, p(' great'[1049])=0.0136, p(' negative'[4633])=0.0099\n",
      "\n",
      "<REVIEW>: This was a bad movie <SENTIMENT>\n",
      "<REVIEW>: This was a bad movie <SENTIMENT> negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative\n",
      "p(answer):  p(' negative'[4633])=0.6349, p(' positive'[3967])=0.0435, p(' bad'[2089])=0.0374, p(' of'[286])=0.0193, p(' not'[407])=0.0059\n",
      "\n",
      "<REVIEW>: This was not a good movie <SENTIMENT>\n",
      "<REVIEW>: This was not a good movie <SENTIMENT> negative negative. I don't know if it was the negative reviews or the negative reviews that made me leave. I was\n",
      "p(answer):  p(' negative'[4633])=0.8781, p(' positive'[3967])=0.0261, p(' bad'[2089])=0.0074, p(' of'[286])=0.0073, p(' worse'[4785])=0.0028\n",
      "\n",
      "<REVIEW>: That movie was garbage <SENTIMENT>\n",
      "<REVIEW>: That movie was garbage <SENTIMENT> negative. I don't know if it was the negative reviews or the negative reviews that made me want to go back to the original\n",
      "p(answer):  p(' negative'[4633])=0.9333, p(' positive'[3967])=0.0663, p(' bad'[2089])=0.0001, p(' Negative'[36183])=0.0, p(' good'[922])=0.0\n",
      "\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT>\n",
      "<REVIEW>: Iphone 7 is not a good phone <SENTIMENT> I am not sure if this is a good or bad thing. I am not sure if this is a good\n",
      "p(answer):  p(' I'[314])=0.0439, p('\n",
      "'[198])=0.0242, p(' but'[475])=0.0222, p(' and'[290])=0.0158, p(' to'[284])=0.0138\n",
      "\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT>\n",
      "<REVIEW>: Google new line of pixels are great <SENTIMENT> positive, but the negative is not. The negative is not positive, it is negative. The negative is negative,\n",
      "p(answer):  p(' positive'[3967])=0.0686, p(' but'[475])=0.0512, p(' negative'[4633])=0.0338, p(' better'[1365])=0.0226, p(' more'[517])=0.0197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    get_answer_tokens=True,\n",
    "    light_weight_tuning= adapter_blocks, algo = \"adapter\"\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('Saved_weights/Fine-Tuned_CLF__IMDB_50K/gpt2-medium/finetuned__epoch_5.pth')\n",
    "print(\"loaded checkpoint\")\n",
    "model.load_state_dict(checkpoint)\n",
    "print(\"loaded model weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    \"This was an awesome movie\",\n",
    "    \"This was a bad movie\",\n",
    "    \"This was not a good movie\",\n",
    "    \"That movie was garbage\",\n",
    "    \"Iphone 7 is not a good phone\",\n",
    "    \"Google new line of pixels are great\"\n",
    "]\n",
    "\n",
    "prompt = [\"<REVIEW>: \" + p + \" <SENTIMENT>\" for p in prompt]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 40,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    "\n",
    "    # track_interesting_words = [\n",
    "    #     [\" positive\", \" negative\"],\n",
    "    #     [\" positive\", \" negative\"]\n",
    "    # ]\n",
    ")\n",
    "\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rome')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3835239043501baad7b502b0573c70a3454f6c2753902e68361683a11a30d10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
